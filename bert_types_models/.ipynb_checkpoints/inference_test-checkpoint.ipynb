{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:19.923736Z",
     "iopub.status.busy": "2022-05-22T22:06:19.922739Z",
     "iopub.status.idle": "2022-05-22T22:06:19.943090Z",
     "shell.execute_reply": "2022-05-22T22:06:19.939153Z",
     "shell.execute_reply.started": "2022-05-22T22:06:19.923736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:21.438229Z",
     "iopub.status.busy": "2022-05-22T22:06:21.437231Z",
     "iopub.status.idle": "2022-05-22T22:06:21.448223Z",
     "shell.execute_reply": "2022-05-22T22:06:21.446265Z",
     "shell.execute_reply.started": "2022-05-22T22:06:21.438229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from setuptools.namespaces import flatten\n",
    "from urllib.parse import urlparse, unquote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:21.848793Z",
     "iopub.status.busy": "2022-05-22T22:06:21.847840Z",
     "iopub.status.idle": "2022-05-22T22:06:21.870837Z",
     "shell.execute_reply": "2022-05-22T22:06:21.868847Z",
     "shell.execute_reply.started": "2022-05-22T22:06:21.848793Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models_trained/bertm_5epochs_dropout/\"\n",
    "TOKENIZER_NAME = \"bert-base-multilingual-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:22.333094Z",
     "iopub.status.busy": "2022-05-22T22:06:22.332094Z",
     "iopub.status.idle": "2022-05-22T22:06:22.767973Z",
     "shell.execute_reply": "2022-05-22T22:06:22.767108Z",
     "shell.execute_reply.started": "2022-05-22T22:06:22.333094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load(MODEL_PATH + \"/model_finetuned.h5\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:22.934876Z",
     "iopub.status.busy": "2022-05-22T22:06:22.933879Z",
     "iopub.status.idle": "2022-05-22T22:06:22.959826Z",
     "shell.execute_reply": "2022-05-22T22:06:22.956867Z",
     "shell.execute_reply.started": "2022-05-22T22:06:22.934876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.0.2 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL_PATH + 'mlb.pickle', 'rb') as handle:\n",
    "    mlb = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:23.738530Z",
     "iopub.status.busy": "2022-05-22T22:06:23.738530Z",
     "iopub.status.idle": "2022-05-22T22:06:23.752527Z",
     "shell.execute_reply": "2022-05-22T22:06:23.751526Z",
     "shell.execute_reply.started": "2022-05-22T22:06:23.738530Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_url(url):\n",
    "    ## convert to urlparse with quoted\n",
    "    url_parsed = urlparse(unquote_plus(url))\n",
    "    ## join all url attributes\n",
    "    url_text = ''.join(x for x in [url_parsed.netloc, url_parsed.path, url_parsed.params, url_parsed.query])\n",
    "    \n",
    "    ## split url to tokens ie: words\n",
    "    tokens = re.split('[- _ % : , / \\. \\+ = ]', url_text)\n",
    "    ## spliting by upper case\n",
    "    \n",
    "    tokens = list(flatten([re.split(r'(?<![A-Z\\W])(?=[A-Z])', s) for s in tokens]))\n",
    "    ## delete token with digits with len < 2\n",
    "    tokens = [token for token in tokens if (not any(c.isdigit() for c in token)) and (not len(token) <=2)]\n",
    "    tokens = [token for token in tokens if token not in ['www', 'html', 'com', 'net', 'org']]\n",
    "    return ' '.join(token for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:24.499016Z",
     "iopub.status.busy": "2022-05-22T22:06:24.498019Z",
     "iopub.status.idle": "2022-05-22T22:06:24.520944Z",
     "shell.execute_reply": "2022-05-22T22:06:24.519989Z",
     "shell.execute_reply.started": "2022-05-22T22:06:24.499016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# urls_cleaned = [preprocess_url(url) for url in URLs]\n",
    "# urls_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:25.237997Z",
     "iopub.status.busy": "2022-05-22T22:06:25.237000Z",
     "iopub.status.idle": "2022-05-22T22:06:25.255924Z",
     "shell.execute_reply": "2022-05-22T22:06:25.254970Z",
     "shell.execute_reply.started": "2022-05-22T22:06:25.237997Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BertCustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T22:06:25.775881Z",
     "iopub.status.busy": "2022-05-22T22:06:25.775881Z",
     "iopub.status.idle": "2022-05-22T22:06:33.925039Z",
     "shell.execute_reply": "2022-05-22T22:06:33.921030Z",
     "shell.execute_reply.started": "2022-05-22T22:06:25.775881Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertCustomModel' object has no attribute 'concat_hidden_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-3b88401c8dde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"attention_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\url-prediction\\camembert_model\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m#### concat hidden states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_hidden_states\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[1;31m## concatenating the hidden states of the last four layers, taking the output from [CLS],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hidden_states'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1186\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertCustomModel' object has no attribute 'concat_hidden_states'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from utils import *\n",
    "\n",
    "\n",
    "URLs = [\n",
    "    \"https://www.logifac.fr/residence/la-residence-gondoles-choisy-le-roi/\",\n",
    "    \"https://www.researchgate.net/publication/352563832_MULTILABEL_OVER-SAMPLING_AND_UNDER-SAMPLING_WITH_CLASS_ALIGNMENT_FOR_IMBALANCED_MULTILABEL_TEXT_CLASSIFICATION\",\n",
    "    \"https://www.cdiscount.com/bricolage/electricite/batterie-plomb-6v-4ah-ova51023e-pour-toplux/f-16614-ova2009927775303.html\",\n",
    "    \"https://www.lequipe.fr/Tennis/TennisFicheJoueur1500000000003017.html\"\n",
    "]\n",
    "\n",
    "urls_cleaned = [preprocess_url(url) for url in URLs]\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    TOKENIZER_NAME, map_location=torch.device(\"cpu\")\n",
    ")\n",
    "inputs = tokenizer(\n",
    "    urls_cleaned,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True,\n",
    "    max_length=40,\n",
    "    return_token_type_ids=False,\n",
    "    padding=\"max_length\",\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "out = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "pred_probs = torch.sigmoid(out).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-22T22:02:15.153925Z",
     "iopub.status.idle": "2022-05-22T22:02:15.155929Z",
     "shell.execute_reply": "2022-05-22T22:02:15.154926Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_bools = np.where(pred_probs > 0.5, 1, 0)\n",
    "pred_bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T21:57:01.389870Z",
     "iopub.status.busy": "2022-05-22T21:57:01.388879Z",
     "iopub.status.idle": "2022-05-22T21:57:01.416839Z",
     "shell.execute_reply": "2022-05-22T21:57:01.414063Z",
     "shell.execute_reply.started": "2022-05-22T21:57:01.389870Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), (), (), ('1077', '294')]\n"
     ]
    }
   ],
   "source": [
    "print(mlb.inverse_transform(pred_bools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T21:59:32.050088Z",
     "iopub.status.busy": "2022-05-22T21:59:32.049136Z",
     "iopub.status.idle": "2022-05-22T21:59:32.077073Z",
     "shell.execute_reply": "2022-05-22T21:59:32.076117Z",
     "shell.execute_reply.started": "2022-05-22T21:59:32.049136Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = 'models_trained/'\n",
    "models_scoring = {}\n",
    "for model_dir in os.listdir(path):\n",
    "    with open(path + model_dir + '/model_scoring.pickle', 'rb') as handle:\n",
    "        models_scoring[model_dir] = pickle.load(handle)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T21:59:32.737167Z",
     "iopub.status.busy": "2022-05-22T21:59:32.736169Z",
     "iopub.status.idle": "2022-05-22T21:59:32.752106Z",
     "shell.execute_reply": "2022-05-22T21:59:32.748170Z",
     "shell.execute_reply.started": "2022-05-22T21:59:32.737167Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_models = models_scoring.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T21:59:50.631694Z",
     "iopub.status.busy": "2022-05-22T21:59:50.630697Z",
     "iopub.status.idle": "2022-05-22T21:59:50.665713Z",
     "shell.execute_reply": "2022-05-22T21:59:50.664711Z",
     "shell.execute_reply.started": "2022-05-22T21:59:50.631694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Hamming loss</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1 score macro</th>\n",
       "      <th>F1 score micro</th>\n",
       "      <th>F1 score weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertm_10epochs_dropout_concat</th>\n",
       "      <td>0.201455</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.766455</td>\n",
       "      <td>0.570676</td>\n",
       "      <td>0.645182</td>\n",
       "      <td>0.631545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertm_5epochs_dropout</th>\n",
       "      <td>0.073055</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>0.611556</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.510260</td>\n",
       "      <td>0.406705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertm_5epochs_dropout_concat</th>\n",
       "      <td>0.187065</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.741633</td>\n",
       "      <td>0.528397</td>\n",
       "      <td>0.638434</td>\n",
       "      <td>0.608079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertm_5epochs_dropout_freezing_concat</th>\n",
       "      <td>0.025142</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>0.537301</td>\n",
       "      <td>0.093941</td>\n",
       "      <td>0.268745</td>\n",
       "      <td>0.197125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertm_5epochs_nodropout</th>\n",
       "      <td>0.077008</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.613980</td>\n",
       "      <td>0.250530</td>\n",
       "      <td>0.515028</td>\n",
       "      <td>0.411921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camembert_5epochs_nodropout</th>\n",
       "      <td>0.047755</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>0.566295</td>\n",
       "      <td>0.134595</td>\n",
       "      <td>0.438133</td>\n",
       "      <td>0.308513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Accuracy  Hamming loss       AUC  \\\n",
       "bertm_10epochs_dropout_concat          0.201455      0.008464  0.766455   \n",
       "bertm_5epochs_dropout                  0.073055      0.009498  0.611556   \n",
       "bertm_5epochs_dropout_concat           0.187065      0.008338  0.741633   \n",
       "bertm_5epochs_dropout_freezing_concat  0.025142      0.011390  0.537301   \n",
       "bertm_5epochs_nodropout                0.077008      0.009460  0.613980   \n",
       "camembert_5epochs_nodropout            0.047755      0.010287  0.566295   \n",
       "\n",
       "                                       F1 score macro  F1 score micro  \\\n",
       "bertm_10epochs_dropout_concat                0.570676        0.645182   \n",
       "bertm_5epochs_dropout                        0.244681        0.510260   \n",
       "bertm_5epochs_dropout_concat                 0.528397        0.638434   \n",
       "bertm_5epochs_dropout_freezing_concat        0.093941        0.268745   \n",
       "bertm_5epochs_nodropout                      0.250530        0.515028   \n",
       "camembert_5epochs_nodropout                  0.134595        0.438133   \n",
       "\n",
       "                                       F1 score weighted  \n",
       "bertm_10epochs_dropout_concat                   0.631545  \n",
       "bertm_5epochs_dropout                           0.406705  \n",
       "bertm_5epochs_dropout_concat                    0.608079  \n",
       "bertm_5epochs_dropout_freezing_concat           0.197125  \n",
       "bertm_5epochs_nodropout                         0.411921  \n",
       "camembert_5epochs_nodropout                     0.308513  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(models_scoring).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T12:12:27.447238Z",
     "iopub.status.busy": "2022-05-22T12:12:27.446233Z",
     "iopub.status.idle": "2022-05-22T12:12:27.465173Z",
     "shell.execute_reply": "2022-05-22T12:12:27.462181Z",
     "shell.execute_reply.started": "2022-05-22T12:12:27.447238Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models_trained/camembert/\"\n",
    "with open(MODEL_PATH + 'model_scoring.pickle', 'rb') as handle:\n",
    "    camembert_scoring = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T12:12:28.435915Z",
     "iopub.status.busy": "2022-05-22T12:12:28.435915Z",
     "iopub.status.idle": "2022-05-22T12:12:28.451949Z",
     "shell.execute_reply": "2022-05-22T12:12:28.450949Z",
     "shell.execute_reply.started": "2022-05-22T12:12:28.435915Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models_trained/bertm/\"\n",
    "with open(MODEL_PATH + 'model_scoring.pickle', 'rb') as handle:\n",
    "    bertm_scoring = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T12:49:01.272439Z",
     "iopub.status.busy": "2022-05-22T12:49:01.270432Z",
     "iopub.status.idle": "2022-05-22T12:49:01.304440Z",
     "shell.execute_reply": "2022-05-22T12:49:01.300436Z",
     "shell.execute_reply.started": "2022-05-22T12:49:01.271482Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'epoch': 1,\n",
       "   'Training Loss': 7.141457376373552e-05,\n",
       "   'Valid. Loss': 0.06411134102120158,\n",
       "   'Accuracy': 0.0,\n",
       "   'Hamming loss': 0.012787648049970042,\n",
       "   'AUC': 0.5,\n",
       "   'F1 score macro': 0.0,\n",
       "   'F1 score micro': 0.0,\n",
       "   'F1 score weighted': 0.0},\n",
       "  {'epoch': 2,\n",
       "   'Training Loss': 3.888661810616196e-05,\n",
       "   'Valid. Loss': 0.045712731004263575,\n",
       "   'Accuracy': 0.01695510849512431,\n",
       "   'Hamming loss': 0.011514970250991935,\n",
       "   'AUC': 0.5176809714597462,\n",
       "   'F1 score macro': 0.03597131995776486,\n",
       "   'F1 score micro': 0.22330721942342266,\n",
       "   'F1 score weighted': 0.12964389450532468},\n",
       "  {'epoch': 3,\n",
       "   'Training Loss': 2.8293338242128762e-05,\n",
       "   'Valid. Loss': 0.03623172285014324,\n",
       "   'Accuracy': 0.037599929719757536,\n",
       "   'Hamming loss': 0.01040516099143838,\n",
       "   'AUC': 0.5572896435698722,\n",
       "   'F1 score macro': 0.11925659326444367,\n",
       "   'F1 score micro': 0.4058319555087931,\n",
       "   'F1 score weighted': 0.2772669519586611},\n",
       "  {'epoch': 4,\n",
       "   'Training Loss': 2.3403512143986206e-05,\n",
       "   'Valid. Loss': 0.03196518123149872,\n",
       "   'Accuracy': 0.05806905033822367,\n",
       "   'Hamming loss': 0.009841866164176094,\n",
       "   'AUC': 0.5865992620198501,\n",
       "   'F1 score macro': 0.18669090876939165,\n",
       "   'F1 score micro': 0.46777694743959297,\n",
       "   'F1 score weighted': 0.3487408419690497},\n",
       "  {'epoch': 5,\n",
       "   'Training Loss': 2.0724025682338184e-05,\n",
       "   'Valid. Loss': 0.02976738926274388,\n",
       "   'Accuracy': 0.07265220065009224,\n",
       "   'Hamming loss': 0.009469736228642424,\n",
       "   'AUC': 0.6146188226036579,\n",
       "   'F1 score macro': 0.2517923441114953,\n",
       "   'F1 score micro': 0.5116649982184367,\n",
       "   'F1 score weighted': 0.40821042049833717}],\n",
       " {'Accuracy': 0.07700822264389627,\n",
       "  'Hamming loss': 0.009460423048040045,\n",
       "  'AUC': 0.6139800825486906,\n",
       "  'F1 score macro': 0.2505295294245177,\n",
       "  'F1 score micro': 0.5150282348655049,\n",
       "  'F1 score weighted': 0.41192136571718857}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertm_scoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
